{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68f19799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector \n",
    "from sqlalchemy import create_engine, inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029471c2",
   "metadata": {},
   "source": [
    "# Connect to MySQL and create a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6ee2630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"root\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "mycursor.execute(\"DROP DATABASE IF EXISTS ubike\")\n",
    "mycursor.execute(\"CREATE DATABASE ubike\")\n",
    "mycursor.execute(\"USE ubike\")\n",
    "\n",
    "mydb.commit()\n",
    "print(\"Changed\")\n",
    "\n",
    "mycursor.close()\n",
    "mydb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4b26f1",
   "metadata": {},
   "source": [
    "# Read CSV files and modify field names simultaneously→Input MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c8aba19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           rent_date_time   rent_date rent_time rent_station return_station  \\\n",
      "0     2023-05-18 12:00:00  2023-05-18  12:00:00  捷運公館站(2號出口)        臺大教研館北側   \n",
      "1     2023-05-18 12:00:00  2023-05-18  12:00:00  捷運公館站(2號出口)    臺大第一活動中心西南側   \n",
      "2     2023-05-18 12:00:00  2023-05-18  12:00:00  捷運公館站(2號出口)        臺大社科院西側   \n",
      "3     2023-05-18 12:00:00  2023-05-18  12:00:00  捷運公館站(2號出口)       基隆長興路口東側   \n",
      "4     2023-05-18 12:00:00  2023-05-18  12:00:00  捷運公館站(2號出口)       臺大新生教室南側   \n",
      "...                   ...         ...       ...          ...            ...   \n",
      "34328 2023-05-05 17:00:00  2023-05-05  17:00:00  捷運公館站(2號出口)      大安運動中心停車場   \n",
      "34329 2023-05-05 17:00:00  2023-05-05  17:00:00  捷運公館站(2號出口)    臺大醫學院附設癌醫中心   \n",
      "34330 2023-05-05 17:00:00  2023-05-05  17:00:00  捷運公館站(2號出口)        臺大社科院西側   \n",
      "34331 2023-05-05 17:00:00  2023-05-05  17:00:00  捷運公館站(2號出口)         和平龍泉街口   \n",
      "34332 2023-05-05 17:00:00  2023-05-05  17:00:00  捷運公館站(2號出口)           文光公園   \n",
      "\n",
      "      rental_period    return_date_time   infodate  \n",
      "0          00:04:30 2023-05-18 12:00:00  2023/5/18  \n",
      "1          00:03:53 2023-05-18 12:00:00  2023/5/18  \n",
      "2          00:06:26 2023-05-18 12:00:00  2023/5/18  \n",
      "3          00:06:55 2023-05-18 12:00:00  2023/5/18  \n",
      "4          00:05:35 2023-05-18 12:00:00  2023/5/18  \n",
      "...             ...                 ...        ...  \n",
      "34328      00:09:18 2023-05-05 17:00:00   2023/5/5  \n",
      "34329      00:11:40 2023-05-05 17:00:00   2023/5/5  \n",
      "34330      00:07:02 2023-05-05 17:00:00   2023/5/5  \n",
      "34331      00:10:28 2023-05-05 17:00:00   2023/5/5  \n",
      "34332      00:14:48 2023-05-05 17:00:00   2023/5/5  \n",
      "\n",
      "[34333 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = r\"C:\\Users\\a4011\\OneDrive\\桌面\\side_project\\Ubike\\Data_Collection\\Rent.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "data['return_time'] = pd.to_datetime(data['return_time'])\n",
    "data['rent_time'] = pd.to_datetime(data['rent_time'])\n",
    "\n",
    "data['rental_period'] = data['rent']\n",
    "data['return_date_time'] = data['return_time']\n",
    "data['rent_date_time'] = data['rent_time']\n",
    "data['rent_date'] = data['rent_time'].dt.date\n",
    "data['rent_time'] = data['rent_time'].dt.time\n",
    "\n",
    "desired_columns = ['rent_date_time', 'rent_date', 'rent_time', 'rent_station', 'return_station', 'rental_period', 'return_date_time', 'infodate']\n",
    "\n",
    "data_rent_index = data[desired_columns]\n",
    "\n",
    "print(data_rent_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ce8f63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been inserted MySQL rent_index table\n"
     ]
    }
   ],
   "source": [
    "host = \"localhost\"\n",
    "user = \"root\"\n",
    "password = \"root\"\n",
    "database = \"ubike\"\n",
    "engine = create_engine(f\"mysql+mysqlconnector://{user}:{password}@{host}/{database}\")\n",
    "\n",
    "table_name = \"rent_index\"\n",
    "\n",
    "inspector = inspect(engine)\n",
    "if inspector.has_table(table_name):\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(f\"DROP TABLE {table_name}\")\n",
    "    print(f\"Deleted existing {table_name} table\")\n",
    "\n",
    "data_rent_index.to_sql(name=table_name, con=engine, if_exists='replace', index=False)\n",
    "print(f\"Data has been inserted MySQL {table_name} table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9818f815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           rent_date_time   rent_date rent_time rent_station return_station  \\\n",
      "0     2023-05-18 09:00:00  2023-05-18  09:00:00   師範大學公館校區_1    捷運公館站(2號出口)   \n",
      "1     2023-05-18 16:00:00  2023-05-18  16:00:00   師範大學公館校區_1    捷運公館站(2號出口)   \n",
      "2     2023-05-18 09:00:00  2023-05-18  09:00:00      景美污水抽水站    捷運公館站(2號出口)   \n",
      "3     2023-05-18 20:00:00  2023-05-18  20:00:00   萬和三號公園(北側)    捷運公館站(2號出口)   \n",
      "4     2023-05-18 12:00:00  2023-05-18  12:00:00         仁愛醫院    捷運公館站(2號出口)   \n",
      "...                   ...         ...       ...          ...            ...   \n",
      "36509 2023-05-26 14:00:00  2023-05-26  14:00:00       寶藏巖觀音亭    捷運公館站(2號出口)   \n",
      "36510 2023-05-26 15:00:00  2023-05-26  15:00:00       寶藏巖觀音亭    捷運公館站(2號出口)   \n",
      "36511 2023-05-26 22:00:00  2023-05-26  22:00:00       臺大椰林小舖    捷運公館站(2號出口)   \n",
      "36512 2023-05-26 18:00:00  2023-05-26  18:00:00     臺大舊體育館西側    捷運公館站(2號出口)   \n",
      "36513 2023-05-26 16:00:00  2023-05-26  16:00:00      臺大工綜館南側    捷運公館站(2號出口)   \n",
      "\n",
      "      rental_period    return_date_time    infodate  \n",
      "0          00:04:40 2023-05-18 10:00:00  2023-05-18  \n",
      "1          01:45:48 2023-05-18 17:00:00  2023-05-18  \n",
      "2          00:03:53 2023-05-18 09:00:00  2023-05-18  \n",
      "3          00:10:12 2023-05-18 20:00:00  2023-05-18  \n",
      "4          00:28:27 2023-05-18 13:00:00  2023-05-18  \n",
      "...             ...                 ...         ...  \n",
      "36509      00:21:14 2023-05-26 14:00:00  2023-05-26  \n",
      "36510      00:04:17 2023-05-26 15:00:00  2023-05-26  \n",
      "36511      00:04:57 2023-05-26 22:00:00  2023-05-26  \n",
      "36512      00:04:10 2023-05-26 18:00:00  2023-05-26  \n",
      "36513      02:06:21 2023-05-26 18:00:00  2023-05-26  \n",
      "\n",
      "[36514 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = r\"C:\\Users\\a4011\\OneDrive\\桌面\\side_project\\Ubike\\Data_Collection\\\\Return.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "data['return_time'] = pd.to_datetime(data['return_time'])\n",
    "data['rent_time'] = pd.to_datetime(data['rent_time'])\n",
    "\n",
    "data['rental_period'] = data['rent']\n",
    "data['return_date_time'] = data['return_time']\n",
    "data['rent_date_time'] = data['rent_time']\n",
    "data['rent_date'] = data['rent_time'].dt.date\n",
    "data['rent_time'] = data['rent_time'].dt.time\n",
    "\n",
    "desired_columns = ['rent_date_time', 'rent_date', 'rent_time', 'rent_station', 'return_station', 'rental_period', 'return_date_time', 'infodate']\n",
    "\n",
    "data_return_index = data[desired_columns]\n",
    "print(data_return_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24d75b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been insertd MySQL  return_index table\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = r\"C:\\Users\\a4011\\OneDrive\\桌面\\side_project\\Ubike\\Data_Collection\\Return.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "data['rent_time'] = pd.to_datetime(data['rent_time'])\n",
    "data['rent_date'] = data['rent_time'].dt.date\n",
    "data['rent_time'] = data['rent_time'].dt.time\n",
    "\n",
    "host = \"localhost\"\n",
    "user = \"root\"\n",
    "password = \"root\"\n",
    "database = \"ubike\"\n",
    "engine = create_engine(f\"mysql+mysqlconnector://{user}:{password}@{host}/{database}\")\n",
    "\n",
    "table_name = \"return_index\"\n",
    "\n",
    "inspector = inspect(engine)\n",
    "\n",
    "if inspector.has_table(table_name):\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(f\"DROP TABLE {table_name}\")\n",
    "    print(f\"Deleted existing {table_name} table\")\n",
    "data_return_index.to_sql(name=table_name, con=engine, if_exists='replace', index=False)\n",
    "print(f\"Data has been insertd MySQL  {table_name} table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53367a34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been insertd MySQL day_condition table\n"
     ]
    }
   ],
   "source": [
    "file_path = r\"C:\\Users\\a4011\\OneDrive\\桌面\\side_project\\Ubike\\Data_Collection\\day_condition.xlsx\"\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "host = \"localhost\"\n",
    "user = \"root\"\n",
    "password = \"root\"\n",
    "database = \"ubike\"\n",
    "engine = create_engine(f\"mysql+mysqlconnector://{user}:{password}@{host}/{database}\")\n",
    "\n",
    "table_name = \"day_condition\"\n",
    "\n",
    "data['date'] = pd.to_datetime(data['date']).dt.date\n",
    "\n",
    "inspector = inspect(engine)\n",
    "if inspector.has_table(table_name):\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(f\"DROP TABLE {table_name}\")\n",
    "    print(f\"Deleted existing {table_name} table\")\n",
    "\n",
    "data.to_sql(name=table_name, con=engine, if_exists='replace', index=False)\n",
    "print(f\"Data has been insertd MySQL {table_name} table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcd7767b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   day_mode rent_time  num_rent  num_return\n",
      "0      A_WS        00      -185          95\n",
      "1      A_WS        01       -41          17\n",
      "2      A_WS        02       -16          10\n",
      "3      A_WS        03        -6           1\n",
      "4      A_WS        04        -8           2\n",
      "..      ...       ...       ...         ...\n",
      "91     D_HR        19      -109          86\n",
      "92     D_HR        20      -101          67\n",
      "93     D_HR        21       -89          67\n",
      "94     D_HR        22       -38          33\n",
      "95     D_HR        23       -40          27\n",
      "\n",
      "[96 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "host = \"localhost\"\n",
    "user = \"root\"\n",
    "password = \"root\"\n",
    "database = \"ubike\"\n",
    "engine = create_engine(f\"mysql+mysqlconnector://{user}:{password}@{host}/{database}\")\n",
    "\n",
    "sql_query = \"\"\"\n",
    "WITH re AS (\n",
    "    SELECT dc.day_mode, rent_time, -COUNT(rent_station) AS num_rent FROM rent_index re\n",
    "    JOIN day_condition dc ON re.rent_date = dc.date\n",
    "    GROUP BY day_mode, rent_time\n",
    "),\n",
    "ru AS (\n",
    "    SELECT dc.day_mode, rent_time, COUNT(rent_station) AS num_return FROM return_index ru\n",
    "    JOIN day_condition dc ON ru.rent_date = dc.date\n",
    "    GROUP BY day_mode, rent_time\n",
    ")\n",
    "\n",
    "\n",
    "SELECT * FROM (\n",
    "SELECT \n",
    "    CASE \n",
    "        WHEN re.day_mode IS NOT NULL THEN re.day_mode\n",
    "        ELSE ru.day_mode\n",
    "    END AS day_mode,\n",
    "    CASE \n",
    "        WHEN re.rent_time IS NOT NULL THEN re.rent_time\n",
    "        ELSE ru.rent_time\n",
    "    END AS rent_time,\n",
    "    IFNULL(re.num_rent, 0) AS num_rent,\n",
    "    IFNULL(ru.num_return, 0) AS num_return\n",
    "FROM re\n",
    "LEFT JOIN ru ON re.day_mode = ru.day_mode AND re.rent_time = ru.rent_time\n",
    "UNION\n",
    "SELECT \n",
    "    CASE \n",
    "        WHEN re.day_mode IS NOT NULL THEN re.day_mode\n",
    "        ELSE ru.day_mode\n",
    "    END AS day_mode,\n",
    "    CASE \n",
    "        WHEN re.rent_time IS NOT NULL THEN re.rent_time\n",
    "        ELSE ru.rent_time\n",
    "    END AS rent_time,\n",
    "    IFNULL(re.num_rent, 0) AS num_rent,\n",
    "    IFNULL(ru.num_return, 0) AS num_return\n",
    "FROM re\n",
    "RIGHT JOIN ru ON re.day_mode = ru.day_mode AND re.rent_time = ru.rent_time\n",
    ") AS union_result\n",
    "ORDER BY day_mode, rent_time;\n",
    "\"\"\"\n",
    "\n",
    "query_result = pd.read_sql(sql_query, con=engine)\n",
    "\n",
    "all_combinations = pd.MultiIndex.from_product([query_result['day_mode'].unique(), query_result['rent_time'].unique()], names=['day_mode', 'rent_time'])\n",
    "\n",
    "merged_result = query_result.set_index(['day_mode', 'rent_time']).reindex(all_combinations, fill_value=0).reset_index()\n",
    "\n",
    "merged_result['rent_time'] = pd.to_timedelta(merged_result['rent_time'])\n",
    "\n",
    "merged_result['rent_time'] = merged_result['rent_time'].dt.components.hours.apply(lambda x: f'{x:02d}')\n",
    "\n",
    "print(merged_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d98349a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   day_mode rent_time  num_rent  num_return  avg_rent  avg_return  net_change\n",
      "0      A_WS        00      -185          95  -11.5625      5.9375     -5.6250\n",
      "1      A_WS        01       -41          17   -2.5625      1.0625     -1.5000\n",
      "2      A_WS        02       -16          10   -1.0000      0.6250     -0.3750\n",
      "3      A_WS        03        -6           1   -0.3750      0.0625     -0.3125\n",
      "4      A_WS        04        -8           2   -0.5000      0.1250     -0.3750\n",
      "..      ...       ...       ...         ...       ...         ...         ...\n",
      "91     D_HR        19      -109          86  -54.5000     43.0000    -11.5000\n",
      "92     D_HR        20      -101          67  -50.5000     33.5000    -17.0000\n",
      "93     D_HR        21       -89          67  -44.5000     33.5000    -11.0000\n",
      "94     D_HR        22       -38          33  -19.0000     16.5000     -2.5000\n",
      "95     D_HR        23       -40          27  -20.0000     13.5000     -6.5000\n",
      "\n",
      "[96 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "def calculate_avg(row, column):\n",
    "    if row['day_mode'].startswith('A_WS'):\n",
    "        return row[column] / 16\n",
    "    elif row['day_mode'].startswith('B_WR'):\n",
    "        return row[column] / 7\n",
    "    elif row['day_mode'].startswith('C_HS'):\n",
    "        return row[column] / 6\n",
    "    elif row['day_mode'].startswith('D_HR'):\n",
    "        return row[column] / 2\n",
    "    else:\n",
    "        return None \n",
    "\n",
    "merged_result['avg_rent'] = merged_result.apply(lambda row: calculate_avg(row, 'num_rent'), axis=1)\n",
    "merged_result['avg_return'] = merged_result.apply(lambda row: calculate_avg(row, 'num_return'), axis=1)\n",
    "merged_result['net_change'] = merged_result['avg_rent'] + merged_result['avg_return']\n",
    "merged_result\n",
    "print(merged_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4158a9bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_result.xlsx 儲存成功\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "excel_file_name = 'merged_result.xlsx'\n",
    "\n",
    "merged_result.to_excel(excel_file_name, index=False)\n",
    "\n",
    "print(f'{excel_file_name} saved successfully')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
